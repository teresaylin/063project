<!DOCTYPE html>
<html><center>
  <h1>PaperCast</h1>
  <h2>Teresa Lin, Erica Yuen</h2>
  <h3>Our idea</h3>
  <p>
    PaperCast is a tool that turns any paper into a podcast and helps you learn even while you're sleeping. <br>Whether you've just pulled an all-nighter and are on your second one, or you've got the post-lunch lull, PaperCast will know when you're falling asleep and will read your paper back to you!
  </p>
  <h3>Presentation Graphics</h3>
  <img src="images/Papercast-final.png" width="600">
  <h3>How it works</h3>
  <p>
    A heart rate sensor clipped onto the user's ear sends continuous heart rate data to an Arduino Micro, which then sends the data to a Raspberry Pi. The Raspberry Pi runs a program to continuously process the data to determine the user's average awake heart rate. If the user falls asleep, his/her heart rate will drop by at least 10 BPM. The program will detect this change and trigger a camera that is attached to the Raspberry Pi to capture an image of the user's paper. After applying unwarping and thresholding, the program uses Pytesseract (a Python wrapper for Google's Tesseract OCR) and Google Text to Speech to transform the image to text, and finally to audio. A speaker module attached to the Raspberry Pi then starts to read the text to the unsuspecting (and unconscious) user!
    <br><br>
    Additionally, anybody on the same network as the Raspberry Pi can connect to a webpage and view the status of the user (awake/asleep), his/her current heart rate, his/her average awake heart rate, and the text that he/she is reading. We hosted our Python server on the Raspberry Pi and set up a static IP and port (192.168.43.152:8000) on a mobile hotspot. However, the IP address is only accessible to users on the hotspot and while the program is running.
  </p>
  <h3>Video</h3>
  <video width="700" controls>
    <source src="videos/FinalVideoTiny.mp4">
    Your video is not compatible with this browser.
  </video>
  <h3>Photos</h3>
  <p>Vel commodo, convallis vivamus, urna ac lacus fusce bibendum sed, amet dolor id tellus wisi duis bibendum, arcu ac ac tincidunt. Tempus lectus sagittis dapibus vel, sit wisi egestas suspendisse morbi, mi non, placerat sapien arcu proident accumsan praesent dui. Sapien sed.</p>
  

  <h1>Weekly Progress Log</h1>

  <h3>Week #1: Sept. 18 - 24</h3>
  <h3>Week #2: Sept. 25 - Oct. 1</h3>
  <h4>HW5: 5 Ideas</h4>
  <img src="images/UrbanExploration.jpg" height="250" width="400">
  <img src="images/Papercast.jpg" height="250" width="400">
  <img src="images/BumpingRings.jpg" height="250" width="400">
  <img src="images/Waiter.jpg" height="250" width="400">
  <img src="images/EmotionalShirts.jpg" height="250" width="400">
  
  <h3>Week #3: Oct. 2 - 8</h3>
  <h3>Week #4: Oct. 9 - 15</h3>
  <a href="https://docs.google.com/presentation/d/14kPEFTG91SIZUYOHI9npAKn0m3VcUbKY_r_TKGWuR80/edit?usp=sharing">HW8: Ideas Presentation</a>
  <p>We took the five ideas from Week 2, created presentation graphics, and presented them!</p>
  <img src="images/5Ideas1.png" height="250" width="400">
  <img src="images/5Ideas2.png" height="250" width="400">
  <img src="images/5Ideas3.png" height="250" width="400">
  <img src="images/5Ideas4.png" height="250" width="400">
  <img src="images/5Ideas5.png" height="250" width="400">
  <h3>Week #5: Oct. 16 - 22</h3>
  <h4>HW10: Chosen Idea</h4>
  <img src="images/Idea1-Papercast.png" height="250" width="400">
  <h4>Goal of PaperCast</h4>
  <p>
    We will be moving forward with PaperCast for our final project.
    PaperCast solves the problem of alerting a reader when he/she is falling
    asleep, or in the very least, helping the reader to learn the content of
    the reading through passive learning via listening to the content. When
    a user is reading a paper or book and starts to drift off, PaperCast turns
    the reading into a podcast and starts to play the reading into the user's
    earbuds or from the computer's speakers.
  </p>
  <h4>How PaperCast fits into the project scope</h4>
  <p>
    We will need to lasercut some sort of eyewear that will hold the camera(s), as well as an enclosure that attaches the eyewear to an ear clip heart rate sensor. We will use a heart rate sensor that detects drops in the user's heart rate, indicating that the user is falling asleep. We will also use cameras to take a photo of the reading when the user is asleep. The data from the heart rate sensor and the photo from the cameras will be sent over wifi. We will process the heart rate data in real time, and if a drop in heart rate is detected, we will use the photo sent from the camera and transcribe the reading into speech. The user input for our project is the user's heart rate.
  </p>
  <h4>Final demo</h4>
  <p>
    For the final demo, we will demo the situation where a user is reading a
    paper and falls asleep. PaperCast should be able to detect when the user
    falls asleep and should quickly start to play the reading aloud to the
    reader. Since it is difficult to live demo falling asleep, we would possibly
    hard code a decrease in heartrate based on previous measurements for the demo,
    or have other sensors such as a decrease in movement using an accelerometer.
  </p>
  <h3>Week #6: Oct. 23 - 29</h3>
  <p>
    We started off with a lot of leftover prototyping materials from other projects, so we already had a Raspberry Pi 2, a wifi adapter for the Raspberry Pi, and an Arduino Micro. We also had the camera from the touchpad pset, so all we had to order for a first prototype was a heart rate sensor. We found a promising candidate, the <a href="http://wiki.seeed.cc/Grove-Ear-clip_Heart_Rate_Sensor/">Grove Ear Clip Heart Rate Sensor</a>. Upon a deeper dive into the specs however, we realized we would also need to get the Grove Base Shield and that shipping would take up to 5 days. We did not want to wait that long, so we found another heart rate sensor on Amazon that did not need a base shield: <a href="https://www.amazon.com/Pulse-Sensor-Real-Original-Best/dp/B01CPP4QM0/ref=sr_1_5?rps=1&ie=UTF8&qid=1509228577&sr=8-5&keywords=heart%20rate%20ear%20clip%20sensor&refinements=p_85%3A2470955011">the Pulse Sensor</a>. This Pulse Sensor heart rate sensor came with an ear clip and was compatible with most Arduinos. We ordered an Arduino Uno just in case, but it turned out to work perfectly fine with the Arduino Micro that we had.
    <br><br>
    In the meantime while we waited for our heart rate sensor, we worked on capturing an image and converting it to audio. We used the camera provided in our touchpad pset. Following <a href="https://www.youtube.com/watch?v=83vFL6d57OI">this tutorial</a>, we converted the image to grayscale and thresholded it using the OpenCV library. Then, we passed the thresholded image into <a href="https://github.com/madmaze/pytesseract">Pytesseract</a>, a Python wrapper for Google's Tesseract OCR, to convert the image to a string. Finally, to play the text from our computers, we discovered that we could use our Macs' Terminal "say" command through the Python os library. We had half of our first prototype done!
    <br><br>
    Next, we booted our Raspberry Pi 2. We followed the setup instructions <a href="https://www.raspberrypi.org/help/noobs-setup/2/">here</a>, which consisted of formatting the SD card, putting the NOOBS files onto the SD card, and booting up the Raspberry Pi. For troubleshooting, we found this guide really useful: <a href="https://elinux.org/R-Pi_Troubleshooting#Red_power_LED_is_on.2C_green_LED_does_not_flash.2C_nothing_on_display">R-Pi Troubleshooting</a>. Note to others and future selves: you need a monitor, keyboard, and mouse!
  </p>
  <h3>Week #7: Oct. 30 - Nov. 5</h3>
  <p>
    Once we had our heart rate sensor, we followed the instructions <a href="https://pulsesensor.com/pages/code-and-guide">here</a> to connect the pins of the sensor to our Arduino microcontroller. We then used PySerial, a Python library, to read the BPM data from the Arduino. (Anything sent to println in Arduino can be read by readline() in PySerial). We had some trouble reading the BPM correctly - on Macs, using PySerial's readline() may send some extra slashes \\, but when you translate to the Raspberry Pi, you can just do readline() without parsing the input for the actual BPM number. Here, we are testing the BPM readings from the heart rate sensor:
    <br>
    <video width="700" controls>
      <source src="videos/HeartRateTestingTiny.mp4">
      Your video is not compatible with this browser.
    </video>
    <br><br>
    We also spent some time understanding the Pulse Sensor - it's an optical sensor, so if there is too little or too much ambient light, it may have a hard time cancelling out the noise. We had to play around with it before we were able to use it quickly without getting too much noise. Pro tip: use the ear clip, and watch the blinks on the Arduino for feedback! If the blinks are slow and steady, you're doing well. If they are quick and spastic, then adjust the sensor until you get the slow and steady blinks.
    <br><br>
    Finally we integrated the reading of BPM data with our earlier work on image to text audio conversion. We manually set a BPM awake threshold (for testing, we set this threshold to be lower than our average heart rate), and if our heart rate dipped below that threshold, then our program would trigger the image processing.
    <br><br>
    Here, we are using BPM data to trigger image capture:
    <br>
    <video width="700" controls>
      <source src="videos/BPMTriggerTestingTiny.mp4">
      Your video is not compatible with this browser.
    </video>
    <br><br>
    This video shows our first pass at converting image to audio:
    <br>
    <video width="700" controls>
      <source src="videos/ImageProcessTestingTiny.mp4">
      Your video is not compatible with this browser.
    </video>
  </p>
  <h3>Week #8: Nov. 6 - 12</h3>
  <a href="https://docs.google.com/presentation/d/16-I5gEO1gVwB2ijLxUpCj21INk5JGG1OYHLhOgb4pQw/edit?usp=sharing">Midterm Presentation</a>
  <p>
    As discussed in our presentation, there were some limitations to our first prototype. The first was that the camera we used did not operate at a high enough resolution to capture a clear image of our text from more than 5 inches away. Positioning the camera within a couple inches of the text would significantly hinder the reader's ability to read while awake, so we needed a camera with a higher resolution.
    <br><br>
    Another limitation was that in order for Pytesseract to correctly transform the image to string, the image needed to be as straight as possible. If it was rotated maybe more than 15 degrees, then Pytesseract would have a really hard time and would spit out gibberish text. For the next iteration, we would need to unwarp warped images and correct any rotation in the image before passing it into Pytesseract.
    <br><br>
    Our main milestones for our next prototype included:<br><br>
    1. Improving calibration of BPM data<br>
    2. Setting up the Raspberry Pi and necessary modules (camera and speaker)<br>
    3. Sending data wirelessly<br>
    4. Improving image processing for more accurate image to text conversion<br>
    5. Improving speech system<br>
    6. Designing a form factor for the entire setup<br>
  </p>
  <h3>Week #9: Nov. 13 - 19</h3>
  <p>
    From our work earlier on processing BPM data, we learned that before gathering data, we needed to calibrate the sensor. We had already implemented one round of calibration, where we gave the sensor 15 seconds to calibrate itself, eliminating some of the noisier BPM data in the beginning. For our next iteration, we added a round of calibration to determine the user's average awake BPM threshold. Once the system has received 15 BPM data points under 95 BPM, it deems the data stable and starts to calculate the user's average heart rate from the next 15 BPM data points. After the average has been calculated, the system sets the awake/asleep BPM threshold equal to: user's average BPM - 10 BPM.* If the system receives 10 BPM data points under this awake/asleep threshold, then it deems the user asleep and triggers the image processing.
    <br><br>
    *Research shows that heart rate drops significantly while asleep: <a href="https://www.livestrong.com/article/105256-normal-heart-rate-sleeping/">Normal Heart Rate Sleeping</a>
  </p>
  <h3>Week #10: Nov. 20 - 26</h3>
  <h3>Week #11: Nov. 27 - Dec. 3</h3>
  <h3>Week #12: Dec. 4 - 10</h3>
  <a href="https://docs.google.com/presentation/d/1yvJKGXxBtHxZM1e3UcwLFDf2uRHcbEwbAgC5nwGftOA/edit?usp=sharing">Final Presentation</a>

  <h3>Week #13: Dec. 11 - 17</h3>

</center>
</html>
